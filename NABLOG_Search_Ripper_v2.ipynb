{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrKonetzko95/NaBlog_Scraper/blob/main/NABLOG_Search_Ripper_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nablog.org Search Ripper\n",
        "\n",
        "This notebook helps to yield every download link from 'k2s'. Either in 4k (2160p) or in any image quality option (if UHD option is not selected).\n",
        "\n",
        "**Steps:**\n",
        "- Insert search teams in the form below.\n",
        "- Check or uncheck UHD option. If selected, only links for 2160p movies will be shown."
      ],
      "metadata": {
        "id": "9Y8REs_SqGoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "def nblog_scrapper(url):\n",
        "  page = requests.get(url)\n",
        "\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "  raw_posts = soup.find_all('div', 'post-header-overview')\n",
        "  \n",
        "  posts_data = []\n",
        "  for p in raw_posts:\n",
        "    post_header = p.find('a', href=True)\n",
        "\n",
        "    post_title = post_header.get('title')\n",
        "\n",
        "    post_link = post_header['href']\n",
        "\n",
        "    p_data = [post_title, post_link]\n",
        "    posts_data.append(p_data)\n",
        "\n",
        "  return posts_data\n",
        "\n",
        "\n",
        "def getDownloadLinks(post_url, UHD):\n",
        "  keywords = [\"k2s\", \"2160p\"] if UHD else [\"k2s\"]\n",
        "\n",
        "  page = requests.get(post_url)\n",
        "\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "  raw_d = soup.find('div', {\"id\": 'download'})\n",
        "\n",
        "  if raw_d is None:\n",
        "    return True\n",
        "\n",
        "  pd_links = [d for d in raw_d]\n",
        "\n",
        "  pd_links = list(filter(lambda x: all(kw in str(x) for kw in keywords), pd_links))\n",
        "\n",
        "  pd_links = list(map(lambda x: str(x).split(\"\\\"\")[1], pd_links))\n",
        "\n",
        "  for link in pd_links:\n",
        "    print(\"Post URL: \", post_url)\n",
        "    print(link)\n",
        "\n",
        "\n",
        "def main_scrapper(search_terms, UHD = True):\n",
        "  page_number = 1\n",
        "  \n",
        "  #links = []\n",
        "  while True: \n",
        "    print(\"Page: \", page_number)\n",
        "    url = \"https://www.naughtyblog.co/page/\" + str(page_number) + \"/?s=\" + search_terms\n",
        "    posts_data = nblog_scrapper(url)\n",
        "\n",
        "    if len(posts_data) == 0:\n",
        "      break\n",
        "\n",
        "    for pd in posts_data:\n",
        "      end = getDownloadLinks(str(pd[1]), UHD)\n",
        "\n",
        "      if end:\n",
        "        break\n",
        "\n",
        "    page_number += 1"
      ],
      "metadata": {
        "id": "lvgJgd32pwo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NABLOG Search Ripper\n",
        "\n",
        "search_terms = 'Type model or site name' #@param {type:\"string\"}\n",
        "\n",
        "search_terms = \"+\".join(search_terms.split(\" \"))\n",
        "\n",
        "UHD = True #@param {type:\"boolean\"}\n",
        "\n",
        "main_scrapper(search_terms, UHD)"
      ],
      "metadata": {
        "id": "d6oGvxFYqCmc",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bf8473-eaad-4c13-871e-0b7d43b8cdd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHZDU7Uppe6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}